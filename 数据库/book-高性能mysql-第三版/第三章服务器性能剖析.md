# 服务器性能剖析
性能相关的灵魂三问
* 如何确认服务器是否达到了性能最佳的状态
* 找出某条语句为什么执行不够快
* 诊断被用户描述成"停顿"、"堆积"或者"卡死"的某些间歇性疑难故障

有一个简单方法：专注于测量服务器时间花费在哪里
技术：性能剖析(profiling)

# 3.1性能优化简介

本书关于性能定义：完成某件任务所需要的时间度量(也即响应时间，注意和吞吐量的区别)


本书数据库服务器目的是执行SQL语句，它关注的任务是查询/语句.
性能用查询(包含DDL,DML)响应时间来度量，单位是每个查询花费的时间。

*性能优化就是在一定的工作负载下尽可能的降低响应时间*

提升每秒查询量，其实是吞吐量优化(定义是单位时间内的查询数量，正好是对性能定义的倒数）。
吞吐量的优化可以看作性能优化的副产品。

*性能优化第二个原则：无法测量就无法有效优化.*(90%时间来测量响应时间花在哪里)

## 3.1.1 通过性能剖析进行优化
性能剖析定义:测试和分析时间花费在哪里的主要方法

两个步骤
* 1.测试任务所花费的时间
* 2.对结果进行统计和排序，讲重要的任务排到前面

性能剖析报告:列出所有任务列表，按照任务消耗时间进行降序排序
* 任务名
* 任务执行时间
* 任务消耗时间
* 任务平均执行时间
* 该任务执行时间占全部时间的百分比
* 等等


两种类型
* 基于执行时间的分析:研究什么任务执行时间最长
* 基于等待的分析:判断任务在什么地方被阻塞的时间最长

## 3.1.2 理解性能剖析
只占总响应时间比重很小的查询是不值得优化的。

性能剖析可能缺失的部分
* 异常情况
* 显示可能的"丢失的时间"
* 被隐藏的细节(性能剖析无法显示所有响应时间的分布)
* 无法再更高层次的堆栈中进行交互式的分析

# 3.2 对应用程序进行性能剖析
性能剖析还是建议自上而下地进行，这样可以追踪用户发起到服务器响应的整个流程

可能影响因素
* 外部资源，调用了外部的web服务/搜索引擎
* 需要处理大量数据,比如分析一个超大的XML文件
* 在循环中执行昂贵的操作，比如滥用正则表达式
* 使用低效算法，比如暴力搜索算法来查找列表中的项

建议所有新项目都考虑包含性能剖析代码(可以在框架层面包含，例如各种埋点,调用链,trace)

# 3.2.1测量PHP应用程序
看看就好了
[Facebook出品 xhprof](http://pecl.php.net/package/xhprof)
[ifp](http://code.google.com/p/instrumentation-for-php)

# 3.3 剖析MySQL查询


## 3.3.1剖析服务器负载

工具:慢查询日志
long_query_time=0 捕获所有查询

问题:
I/O开销可以忽略不计
日志可能消耗大量的磁盘空间->部署日志轮转(long rotation)工具

假如线上权限不足，导致无法再服务器记录查询怎么办呢?
### 通过Percona Toolkit中的pt-query-digest，--processlist选项不断查看
SHOW FULL PROCESSLIST输出
### 通过抓取TCP网络包(tcpdump),根据Mysql C/S通讯协议进行解析
然后使用pt-query-digest --type=tcpdump选项来解析并分析查询

### 动过mysql proxy代理层脚本记录所有查询


直接用pt-query-digest工具分析慢sql日志
`pt-query-digest slow.log`
```
chujun@chujundeMacBook-Pro  /tmp  pt-query-digest /tmp/logs/mysql/data/slow.log

# 200ms user time, 40ms system time, 28.95M rss, 4.11G vsz
# Current date: Fri Sep 25 19:01:15 2020
# Hostname: chujundeMacBook-Pro.local
# Files: /tmp/logs/mysql/data/slow.log
# Overall: 6 total, 2 unique, 0.01 QPS, 0.01x concurrency ________________
# Time range: 2020-09-25T09:22:00 to 2020-09-25T09:36:35
# Attribute          total     min     max     avg     95%  stddev  median
# ============     ======= ======= ======= ======= ======= ======= =======
# Exec time             7s   370ms      2s      1s      2s   668ms      2s
# Lock time          787us       0   441us   131us   424us   159us   168us
# Rows sent             93       1      30   15.50   28.75   13.88   28.75
# Rows examine       2.86M       1 976.59k 488.30k 961.27k 480.63k 961.27k
# Query size           198      15      51      33   49.17   17.33   49.17

# Profile
# Rank Query ID                           Response time Calls R/Call V/M
# ==== ================================== ============= ===== ====== =====
#    1 0x59A74D08D407B5EDF9A57DD5A41825CA  5.0058 68.9%     3 1.6686  0.13 SELECT
#    2 0xCBBA82FAFC6C856720133BF496BEC056  2.2621 31.1%     3 0.7540  0.36 SELECT t_user

# Query 1: 0.12 QPS, 0.21x concurrency, ID 0x59A74D08D407B5EDF9A57DD5A41825CA at byte 409
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.13
# Time range: 2020-09-25T09:22:00 to 2020-09-25T09:22:24
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         50       3
# Exec time     68      5s      1s      2s      2s      2s   458ms      2s
# Lock time      0       0       0       0       0       0       0       0
# Rows sent      3       3       1       1       1       1       0       1
# Rows examine   0       3       1       1       1       1       0       1
# Query size    22      45      15      15      15      15       0      15
# String:
# Databases    trade_in_center
# Hosts        localhost
# Users        root
# Query_time distribution
#   1us
#  10us
# 100us
#   1ms
#  10ms
# 100ms
#    1s  ################################################################
#  10s+
# EXPLAIN /*!50100 PARTITIONS*/
select SLEEP(2)\G

# Query 2: 0.11 QPS, 0.08x concurrency, ID 0xCBBA82FAFC6C856720133BF496BEC056 at byte 835
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.36
# Time range: 2020-09-25T09:36:08 to 2020-09-25T09:36:35
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         50       3
# Exec time     31      2s   370ms      2s   754ms      1s   519ms   374ms
# Lock time    100   787us    93us   441us   262us   424us   136us   247us
# Rows sent     96      90      30      30      30      30       0      30
# Rows examine  99   2.86M 976.59k 976.59k 976.59k 976.59k       0 976.59k
# Query size    77     153      51      51      51      51       0      51
# String:
# Databases    trade_in_center
# Hosts        localhost
# Users        root
# Query_time distribution
#   1us
#  10us
# 100us
#   1ms
#  10ms
# 100ms  ################################################################
#    1s  ################################
#  10s+
# Tables
#    SHOW TABLE STATUS FROM `trade_in_center` LIKE 't_user'\G
#    SHOW CREATE TABLE `trade_in_center`.`t_user`\G
# EXPLAIN /*!50100 PARTITIONS*/
select * from t_user  order by create_time limit 30\G
 chujun@chujundeMacBook-Pro  /tmp 
```

报告结果分析见[MySQL慢查询（二） - pt-query-digest详解慢查询日志](https://www.cnblogs.com/luyucheng/p/6265873.html)

## 3.3.2 剖析单条查询
本小节目标:测量查询执行各部分花费了多少时间---->有这些数据才能决定采用何种优化
书籍版本5.5能提供的方法
* SHOW STATUS
* SHOW PROFILE
* 慢查询日志

# 资料
* [percona](https://www.percona.com)
* 关于性能优化的描述[Goal driven performance optimization](https://www.percona.com/blog/2008/12/22/goal-driven-performance-optimization/)
* [percona toolkit github](https://github.com/percona/percona-toolkit)
* [MySQL慢查询（二） - pt-query-digest详解慢查询日志](https://www.cnblogs.com/luyucheng/p/6265873.html)